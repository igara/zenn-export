---
title: "ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰èµ·å‹•ã—ãŸã‚«ãƒ¡ãƒ©ã§TCGã®ã‚«ãƒ¼ãƒ‰ã‚’è­˜åˆ¥ã™ã‚‹æ–¹æ³•"
emoji: "ğŸ´"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["nodejs", "tensorflowjs", "canvas", "react", "tcg"]
published: true
---

# ã“ã®è¨˜äº‹ã«ã¤ã„ã¦

æœ€è¿‘ã€TCG(ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ )ã‚‚éŠæˆ¯ç‹ã¯[ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¥ã‚¨ãƒ«](https://www.konami.com/yugioh/masterduel/jp/ja/)ã€ãƒã‚±ãƒ¢ãƒ³ã¯[ãƒã‚±ãƒã‚±](https://www.pokemontcgpocket.com/ja/)ã¨ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã•ã‚ŒãŸã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã®ã‚‚ã®ãŒå¢—ãˆã¦ãã¾ã—ãŸã­ï¼

æœ€è¿‘è‡ªåˆ†ãŒãƒãƒã£ã¦ã‚„ã£ã¦ã„ã‚‹ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã¯[è‹±å‚‘å¤§æˆ¦](https://www.eiketsu-taisen.com/)ã¨ã„ã†ã‚²ãƒ¼ãƒ ã‚»ãƒ³ã‚¿ãƒ¼ã®ã‚¢ãƒ¼ã‚±ãƒ¼ãƒ‰æ©Ÿã§éŠã¶ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã§ã€å€‹äººãƒ„ãƒ¼ãƒ«ã¨ã—ã¦[è‹±å‚‘å¤§æˆ¦ãƒ„ãƒ¼ãƒ«](https://igara.github.io/eiketsu-taisen-tool/)ã¨ã„ã†ã®ã‚’ä½œã£ã¦ã„ã‚‹ã®ã§ã™ãŒã€ãƒ‡ãƒƒã‚­æ§‹æˆã™ã‚‹ã¨ãã«ã‚«ãƒ¡ãƒ©ã‹ã‚‰ä½œæˆã§ãã‚‹ã‚‚ã®ã‚‚ã‚ã£ãŸã‚‰ä¾¿åˆ©ãã†ã¨æ€ã„ã€å®Ÿè·µã—ã¦ã¿ãŸã¨ã„ã†è¨˜äº‹ã«ãªã‚Šã¾ã™ã€‚(ã“ã®ã‚²ãƒ¼ãƒ ã€[åœŸæ–¹æ­³ä¸‰](https://igara.github.io/eiketsu-taisen-tool/?searchWord=%E5%9C%9F%E6%96%B9%E6%AD%B3%E4%B8%89)ãŒã‚¤ãƒ©ã‚¹ãƒˆé•ã„ã§è¤‡æ•°ã‚ã£ãŸã‚Šã€å§“ãŒ[æº](https://igara.github.io/eiketsu-taisen-tool/?searchWord=%E3%81%BF%E3%81%AA%E3%82%82%E3%81%A8)ã€[å¹³](https://igara.github.io/eiketsu-taisen-tool/?searchWord=%E3%81%9F%E3%81%84%E3%82%89)ã€[åŒ—æ¡](https://igara.github.io/eiketsu-taisen-tool/?searchWord=%E5%8C%97%E6%9D%A1)ã€[å³¶æ´¥](https://igara.github.io/eiketsu-taisen-tool/?searchWord=%E5%B3%B6%E6%B4%A5)ãŒå¤šãã¦ç”»åƒã§æ¤œç´¢ã§ãã‚‹ã‚‚ã®ä½œã£ãŸæ–¹ãŒåŠ©ã‹ã‚‹ã¨æ€ã£ãŸã®ã‚‚ã‚ã‚‹)

# ã§ããŸã‚‚ã®

[è‹±å‚‘ã‚«ãƒ¡ãƒ©](https://igara.github.io/eiketsu-taisen-tool/camera)

![è‡ªåˆ†ã®Androidã§ã®å‹•ä½œã‚¹ã‚¯ã‚·ãƒ§](/images/tcg_recognition_browser_camera/self_android.jpg)

ä¸Šè¨˜ã¯è‡ªåˆ†ã®Pixel 8aã§æ’®ã£ãŸæœ€æ–°ã®è‹±å‚‘ã‚«ãƒ¡ãƒ©UIã§ã®ã‚¹ã‚¯ã‚·ãƒ§ã«ãªã‚Šã¾ã™ã€‚
é»’ãŒå¤šã„ã‚¤ãƒ©ã‚¹ãƒˆã®è­˜åˆ¥ã‚„ã€ERã‚«ãƒ¼ãƒ‰ã®ã‚ˆã†ãªãƒ›ãƒ­ã‚°ãƒ©ãƒ å°åˆ·ã‚„ã‚¹ãƒªãƒ¼ãƒ–ã‚„ãƒ­ãƒ¼ãƒ€ãªã©ã®ã‚«ãƒ¼ãƒ‰ã®ã‚«ãƒãƒ¼ã§å…‰æ²¢ã®ã‚ã‚‹ã‚«ãƒ¼ãƒ‰ã‚ã£ã¦ã‚‚è­˜åˆ¥ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚

![å‹äººã®iPhoneã§ã®å‹•ä½œã‚¹ã‚¯ã‚·ãƒ§](/images/tcg_recognition_browser_camera/freand_iphone.jpg)

ä¸Šè¨˜ã¯å‹äººã®iPhoneã®ã‚¹ã‚¯ã‚·ãƒ§ã§ã€å¤ã„UIã®è‹±å‚‘ã‚«ãƒ¡ãƒ©ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ãªã‚Šã¾ã™ãŒã€
æš—ã„å ´åˆã«è©¦ã—ã¦ã‚‚ã‚«ãƒ¼ãƒ‰æ¤œå‡ºã™ã‚‹ã“ã¨ã«æˆåŠŸã—ã¾ã—ãŸã€‚

# è§£èª¬

ã“ã“ã‹ã‚‰ã¯ç”»åƒèªè­˜ã™ã‚‹ãŸã‚ã®å®Ÿè£…ã‚’è¨˜è¼‰ã—ã¾ã™ãŒã€ä½¿ç”¨ã—ãŸå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½œæˆã¨Webãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®å®Ÿè£…ã‚’åˆ†ã‘ã¦è§£èª¬ã—ã¦ã„ãã¾ã™ã€‚

## å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½œæˆ

å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½œæˆã«å¿…è¦ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã—ã¦[import_cardtfmodel.ts](https://github.com/igara/eiketsu-taisen-tool/blob/main/data/import_cardtfmodel.ts)ã‚’ä½œæˆã—ã¾ã—ãŸã€‚

### å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å¿…è¦ãªç”»åƒãƒ‡ãƒ¼ã‚¿ä½œæˆ

```bash
$ node --experimental-strip-types import_cardtfmodel.ts --cardImageTFModelForImage
```

ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã‚’å…ƒã«ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚

:::details ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã®ç”»åƒåŠ å·¥å‡¦ç†
```typescript
for (const general of GeneralJSON) {
  const dirName = `data/generals/${general.color.name}/${general.no}_${general.name}`;
  const input2Path = `${dirName}/2.jpg`;

  let i = 6;

  await glossGradientHorizonTop({ dirName, inputPath: input2Path, i: i++ });
  ...çœç•¥
  await createDarkenedImageGlossGradientRightBottom({
    dirName,
    inputPath: input2Path,
    i: i++,
  });
}
```
:::

ã¨ã„ã†ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã¯å…ƒã®ã‚«ãƒ¼ãƒ‰ç”»åƒã«å¯¾ã—ã¦ã€ã„ã‚ã‚“ãªè§’åº¦ã§å…‰ãŒã‚ã£ãŸã‹ã®ã‚ˆã†ãªã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ä»˜ã„ãŸç”»åƒã‚’[node-canvas](https://www.npmjs.com/package/canvas)ã§ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚

ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒã¨ã—ã¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªã€

![ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒ](/images/tcg_recognition_browser_camera/gradetion_image.jpg)

ç¸¦ã€æ¨ªã€æ–œã‚ã«ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…¥ã‚ŒãŸã‚ˆã†ãª12æšã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚
ä»–ã«ã¯å‹äººã®iPhoneã®ã‚¹ã‚¯ã‚·ãƒ§ã®ã‚ˆã†ã«æš—ã„ã‚«ãƒ¡ãƒ©ç’°å¢ƒè€ƒæ…®ã¨ã—ã¦ã€å…ƒã®ã‚«ãƒ¼ãƒ‰ã«é»’ã§ãƒã‚¹ã‚¯åŒ–ã—ãŸã‚‚ã®ã«ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…¥ã‚ŒãŸç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚

[GitHubã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ç”»åƒ](https://github.com/igara/eiketsu-taisen-tool/tree/main/data/data/generals/%E7%8E%84/EX002_%E7%9B%B8%E6%A5%BD%E7%B7%8F%E4%B8%89)ã®6~80.jpgã¯å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è€ƒæ…®ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸç”»åƒã«ãªã‚Šã¾ã™ã€‚

å‰å›ã®[ImageHashã‚’ç”¨ã„ãŸç”»åƒè­˜åˆ¥ã®è¨˜äº‹](https://zenn.dev/igara/articles/youtube_eiketsu_deck)ã¨ã¯é•ã„ã€ã‚«ãƒ¡ãƒ©ã®ç’°å¢ƒã«ã‚ˆã‚‹å…¥åŠ›ã®ç”»åƒãŒç•°ãªã‚‹ãŸã‚ã€æ¤œå‡ºã™ã‚‹ãŸã‚ã®ã‚«ãƒ¼ãƒ‰ã®ç”»åƒã‚‚å¤šã‚ã«ãªã‚Šã¾ã—ãŸã€‚

### å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½œæˆ

```bash
$ node --experimental-strip-types import_cardtfmodel.ts --cardImageTFModel
```

ã“ã¡ã‚‰ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯[@tensorflow/tfjs-node](https://www.npmjs.com/package/@tensorflow/tfjs-node)ã‚’ä½¿ã£ãŸå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ãªã‚Šã¾ã™ã€‚

å®Ÿè£…æ–¹æ³•ã¨ã‹æœ€åˆã‚ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸãŒChatGPTã§èããªãŒã‚‰å®Ÿè£…ã—ã€ç†è§£ã—ã¦ã„ãã¾ã—ãŸã€‚
 
:::details ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒ†ãƒ³ã‚½ãƒ«åŒ–ã¨ãƒ©ãƒ™ãƒ«ä»˜ã‘
```typescript
async function loadImageToTensor(imagePath: string) {
  const image = (await Canvas.loadImage(
    imagePath,
  )) as unknown as HTMLImageElement;
  const canvas = Canvas.createCanvas(
    image.width,
    image.height,
  ) as unknown as HTMLCanvasElement;
  const ctx = canvas.getContext("2d");
  if (!ctx) return;
  ctx.drawImage(image, 0, 0);
  const tensor = tf.browser
    .fromPixels(canvas)
    .resizeNearestNeighbor([cardSize.width, cardSize.height])
    .toFloat()
    .div(tf.scalar(255.0));
  return tensor;
}

async function loadImagesFromDirectories() {
  const generalsJSON: General[] = JSON.parse(
    fs.readFileSync("data/json/generals.json", "utf8"),
  );

  const classNames = [];
  const images: tf.Tensor<tf.Rank>[] = [];
  const labels = [];

  for (const general of generalsJSON) {
    const className = `${general.color.name}_${general.no}_${general.name}`;
    classNames.push(className);

    // ãƒ¢ãƒ‡ãƒ«ã«ä½¿ç”¨ã™ã‚‹ç”»åƒã®èª­ã¿è¾¼ã¿ãƒ«ãƒ¼ãƒ—
    for (const i of Array(81).keys()) {
      // ãƒ¢ãƒ‡ãƒ«ã«ä½¿ç”¨ã—ãªã„ç”»åƒã‚’ã‚¹ã‚­ãƒƒãƒ—
      if (i === 0) continue;
      if (i === 1) continue;
      if (i === 3) continue;

      const filePath = `data/generals/${general.color.name}/${general.no}_${general.name}/${i}.jpg`;
      const tensor = await loadImageToTensor(filePath);
      if (!tensor) continue;
      images.push(tensor);
      labels.push(classNames.indexOf(className));
    }
  }

  const xs = tf.stack(images);
  const ys = tf.tensor(labels, [labels.length, 1]);
  return { xs, ys, classNames };
}
```
:::

æ­£ç›´ãƒ†ãƒ³ã‚½ãƒ«åŒ–ã®ç®‡æ‰€ã¯ChatGPTã®ã‚³ãƒ”ãƒšã§ã™ãŒå¿…è¦ãªç”»åƒã ã‘èª­ã¿è¾¼ã¿ã—ã‚ˆã†ã¨ã™ã‚‹ãŸã‚ã®å‡¦ç†ã ã‘è¿½åŠ ã—ã¦ã„ã¾ã™ã€‚

:::details ãƒ†ãƒ³ã‚½ãƒ«åŒ–å¾Œã®ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ä¿å­˜å‡¦ç†
```typescript
const { xs, ys, classNames } = await loadImagesFromDirectories();

// ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
const model = tf.sequential();
model.add(
  tf.layers.conv2d({
    inputShape: [cardSize.width, cardSize.height, 3],
    filters: 8,
    kernelSize: 3,
    activation: "relu",
  }),
);
model.add(tf.layers.maxPooling2d({ poolSize: 2, strides: 2 }));
model.add(
  tf.layers.conv2d({ filters: 16, kernelSize: 3, activation: "relu" }),
);
model.add(tf.layers.maxPooling2d({ poolSize: 2, strides: 2 }));
model.add(tf.layers.flatten());
model.add(
  tf.layers.dense({ units: classNames.length, activation: "softmax" }),
);

// ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
model.compile({
  optimizer: "adam",
  loss: "sparseCategoricalCrossentropy",
  metrics: ["accuracy"],
});

// ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
await model.fit(xs, ys, { epochs: 10 });

// ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
await model.save("file://./general-image"); // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
console.log("ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ");
```
:::

:::message alert
ã“ã“ã§æ³¨æ„ã™ã¹ããªã®ãŒãƒ†ãƒ³ã‚½ãƒ«åŒ–ã™ã‚‹éš›ã«ã‚‚ã€ãƒªã‚µã‚¤ã‚ºã®å‡¦ç†ã§ã‚‚`cardSize.width, cardSize.height`ã¨ã„ã†è¨˜è¼‰ãŒã‚ã‚Šã¾ã—ãŸãŒã“ã®ã‚µã‚¤ã‚ºãŒãƒ¢ãƒ‡ãƒ«ã®å¤§ãã•ã«ã‚‚å½±éŸ¿ã™ã‚‹ãŸã‚ã€é©åˆ‡ãªã‚µã‚¤ã‚ºã«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

å…·ä½“çš„ã«ã¯ã€æœ€åˆï¼ˆç¾åœ¨ã¾ãŸã‚«ãƒ¼ãƒ‰å¢—ãˆãŸã‚Šã€ãƒ¢ãƒ‡ãƒ«ä½œæˆè€ƒæ…®ã§ãƒ¢ãƒ‡ãƒ«ç”»åƒãŒå°‘ãªã‹ã£ãŸæ™‚ä»£ï¼‰ã¯

- width
  - 140(ç¾åœ¨64)
- height
  - 215(ç¾åœ¨102)

ãªã‚«ãƒ¼ãƒ‰ã®ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å¤§ãã•ã‚’æŒ‡å®šã—ã€å½“åˆã‚«ãƒ¼ãƒ‰æšæ•°868æš * ãƒ¢ãƒ‡ãƒ«ç”»åƒ30æšã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ãŸã‚‰ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºãŒ`1GB`è¿‘ãã«ãªã‚Šã€Webãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ã‚‚èª­ã¿è¾¼ã¿ã®æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã¨èª­ã¿è¾¼ã¿ãŒçµ‚ã‚ã£ã¦ã‹ã‚‰ã‚‚ç”»åƒã®æ¯”è¼ƒã®ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ã€ãƒ¢ãƒã‚¤ãƒ«ã§ã¯è§£æã«æ™‚é–“ãŒã‹ã‹ã‚‹ã¨ã„ã†å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸã®ã§é©åˆ‡ãªãƒªã‚µã‚¤ã‚ºã®ã‚µã‚¤ã‚ºæŒ‡å®šãŒå¿…è¦ã§ã™ã€‚

ç¾åœ¨ã¯20MBã¾ã§ã«è½ã¡ç€ãã€è§£æã‚‚ã ã„ã¶é€Ÿããªã‚Šã¾ã—ãŸã€‚
:::

### å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆ†å‰²
ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’Webãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ã‚‚ä½¿ã„ã‚„ã™ãã€Git LFSã‚’ä½¿ã‚ãšã«Gitç®¡ç†ã™ã‚‹ãŸã‚ã«åˆ†å‰²ã—ã¦ã„ã¾ã™ã€‚

åˆ†å‰²ã™ã‚‹ãŸã‚ã«[tensorflowjs_converter](https://github.com/tensorflow/tfjs/tree/master/tfjs-converter)ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

Pythonã¯3.6.8ã‚’ä½¿ã£ã¦ãŠã‚Šã€
numpyã«é–¢ã—ã¦ã¯

[AttributeError: module 'numpy' has no attribute 'XXX' ã‚¨ãƒ©ãƒ¼ã®è§£æ±ºãƒ­ã‚°](https://qiita.com/yusuke_s_yusuke/items/bf7ce2deb6153ab0123b)ã«ã‚ã‚‹å•é¡ŒãŒã‚ã‚‹ãŸã‚æ±ºã¾ã£ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã‚‹ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã—ã¦ã„ã¾ã™ã€‚

```bash
$ pip install numpy==1.26.4
$ pip install tensorflowjs==3.18.0
```

å¿…è¦ãªã‚‚ã®ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸå¾Œã¯ä¸‹è¨˜ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’åˆ†å‰²ã—ã¾ã™ã€‚

```bash
$ tensorflowjs_converter --input_format=tfjs_layers_model --output_format=tfjs_layers_model --weight_shard_size_bytes=10485760 ./general-image/model.json ../app/public/tensorflow/general-image
```

`weight_shard_size_bytes`ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§å¥½ããªã‚µã‚¤ã‚ºã«åˆ†å‰²ã§ãã¾ã™ã€‚


## Webãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…

### å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’Contextã«ã™ã‚‹

::: details Contextã®ä½œæˆ
```typescript
"use client";

import * as tf from "@tensorflow/tfjs";
import React from "react";
import { createContext } from "react";

export interface GeneralCardImageTFModelProviderProps {
  children: React.ReactNode;
}

const GeneralCardImageTFModelContext = createContext<{
  generalCardImageTFModel: tf.LayersModel | null;
}>({
  generalCardImageTFModel: null,
});

function GeneralCardImageTFModelProvider({
  children,
}: GeneralCardImageTFModelProviderProps) {
  const [generalCardImageTFModel, setGeneralCardImageTFModel] =
    React.useState<tf.LayersModel | null>(null);

  React.useEffect(() => {
    const loadModel = async () => {
      const loadedModel = await tf.loadLayersModel(
        "/eiketsu-taisen-tool/tensorflow/general-image/model.json",
      );
      setGeneralCardImageTFModel(loadedModel);
    };
    loadModel();
  }, []);

  return (
    <GeneralCardImageTFModelContext.Provider
      value={{
        generalCardImageTFModel,
      }}
    >
      {children}
    </GeneralCardImageTFModelContext.Provider>
  );
}

export { GeneralCardImageTFModelContext, GeneralCardImageTFModelProvider };

```
:::

```typescript
const { generalCardImageTFModel } = React.useContext(
  GeneralCardImageTFModelContext,
);
```

ã‹ã‚‰äº‹å‰ã«èª­ã¿è¾¼ã¿æ¸ˆã¿ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã‚„ã™ãã—ã¾ã™ã€‚

### ãƒšãƒ¼ã‚¸ã®ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…

[index.tsx](https://github.com/igara/eiketsu-taisen-tool/blob/main/app/src/components/pages/camera/CameraAnalyze/index.tsx)ã€[logic.tsx](https://github.com/igara/eiketsu-taisen-tool/blob/main/app/src/components/pages/camera/CameraAnalyze/logic.tsx)ã®è§£èª¬ã«ãªã‚Šã¾ã™ã€‚

index.tsxã¯ä¸»ã«UIã®å®Ÿè£…ã€logic.tsxã¯é›‘ã«å‡¦ç†ã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚

#### ä½¿ç”¨ã§ãã‚‹ã‚«ãƒ¡ãƒ©æƒ…å ±ã®å–å¾—

:::details ã‚«ãƒ¡ãƒ©æƒ…å ±å–å¾—
```typescript
const { generalCardImageTFModel } = React.useContext(
  GeneralCardImageTFModelContext,
);
const [devices, setDevices] = React.useState<MediaDeviceInfo[]>([]);

React.useEffect(() => {
  if (!generalCardImageTFModel) return;

  const getDevices = async () => {
    try {
      await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: false,
      });

      const enumerateDevices =
        await window.navigator.mediaDevices.enumerateDevices();
      setDevices(
        enumerateDevices.filter(
          (device) => device.kind === "videoinput" && device.label,
        ),
      );
    } catch (_) {}
  };
  getDevices();
}, [generalCardImageTFModel]);
```
:::

ä½¿ç”¨ã§ãã‚‹ã‚«ãƒ¡ãƒ©ã®æƒ…å ±ã¯å…¨ã¦ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰é¸æŠã§ãã‚‹ã‚ˆã†ã«å–å¾—ã—ã¦ã„ã¾ã™ã€‚
æœ€åˆã¯OBS Virtual Cameraã§ãƒ†ã‚¹ãƒˆã—ã¦ã„ãŸã¨ã„ã†é–‹ç™ºãƒã‚¿ã‚‚ã‚ã‚Šã¾ã—ãŸã€‚(è‰²ã€…ãƒã‚¤ã‚ºã®ãªã„ç”»åƒã§ã‚‚æ­£ã—ãæ¤œçŸ¥ã§ãã‚‹ã‹ç¢ºèªã—ãŸã„ã¨ãã«ä¾¿åˆ©)

:::details ã‚«ãƒ¡ãƒ©é¸æŠå‡¦ç†
```typescript
const refVideo = React.useRef<HTMLVideoElement>(null);
const [device, setDivice] = React.useState<MediaDeviceInfo | null>(null);
const [isVideo, setIsVideo] = React.useState(false);

React.useEffect(() => {
  if (!device) return;

  if (!refVideo) return;
  if (!refVideo.current) return;

  const video = refVideo.current;

  const check = async () => {
    try {
      if (!window.navigator.mediaDevices.getUserMedia) return;

      const stream = await window.navigator.mediaDevices.getUserMedia({
        audio: false,
        video: {
          deviceId: device.deviceId,
        },
      });
      video.srcObject = stream;

      video.addEventListener("loadedmetadata", () => {
        setIsVideo(true);
      });
    } catch (e) {
      console.error(e);
    }
  };
  check();
}, [device]);
```
:::

`video.addEventListener("loadedmetadata")`ã—ã¦åˆã‚ã¦ã‚«ãƒ¡ãƒ©ã®æ˜ åƒãŒvideoã«èª­ã¿è¾¼ã¾ã‚Œã‚‹ãŸã‚åˆ¥ã§`isVideo`ã‚’çŠ¶æ…‹ç®¡ç†ã—ã¦ã„ã¾ã™ã€‚

#### é¸æŠã—ãŸã‚«ãƒ¡ãƒ©ã®æ˜ åƒã‚’canvasåŒ–ã™ã‚‹

å¾Œã«ã‚«ãƒ¡ãƒ©ã®æ˜ åƒã«å¯¾ã—ã¦é¸æŠç¯„å›²æŒ‡å®šã®æ ã‚’æç”»ã™ã‚‹ãŸã‚ã«canvasåŒ–ã—ã¦ã„ã¾ã™ã€‚

ãã®ãŸã‚ã€ã‚«ãƒ¡ãƒ©ã®æ˜ åƒã¯`video`ã‚¿ã‚°ã§æ˜ ã—ã¦ã„ã¾ã™ãŒã€

```typescript
<video muted autoPlay playsInline ref={refVideo} className="h-0" />
```

ã¨è¦‹ãˆãªã„ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

:::details canvasåŒ–ã¨é¸æŠç¯„å›²ã®æç”»
```typescript
const refVideoCanvas = React.useRef<HTMLCanvasElement>(null);
const [selectedVideoCanvasPosition, setSelectedVideoCanvasPosition] =
  React.useState({
    from: {
      x: 0,
      y: 0,
    },
    to: {
      x: 0,
      y: 0,
    },
  });

const detectAndResizeCard = () => {
  if (!generalCardImageTFModel) return;
  if (!isVideo) return;

  if (!refVideo.current) return;
  const video = refVideo.current;

  if (!refVideoCanvas.current) return;
  const videoCanvas = refVideoCanvas.current;
  const videoCanvasContext = videoCanvas.getContext("2d", {
    willReadFrequently: true,
  });
  if (!videoCanvasContext) return;

  try {
    const frameWidth = video.videoWidth;
    const frameHeight = video.videoHeight;

    videoCanvas.width = frameWidth;
    videoCanvas.height = frameHeight;
    videoCanvasContext.drawImage(video, 0, 0, frameWidth, frameHeight);

    // çŸ©å½¢é¸æŠã«åŸºã¥ã„ãŸç·šã‚’æç”»
    const { from, to } = selectedVideoCanvasPosition;
    videoCanvasContext.beginPath();
    videoCanvasContext.rect(from.x, from.y, to.x - from.x, to.y - from.y);
    videoCanvasContext.strokeStyle = "red"; // ç·šã®è‰²ã‚’è¨­å®š
    videoCanvasContext.lineWidth = 2; // ç·šã®å¤ªã•ã‚’è¨­å®š
    videoCanvasContext.stroke();
  } catch (e) {
    console.error(e);
  }
};

React.useEffect(() => {
  if (!isVideo) return;

  const intervalId = setInterval(detectAndResizeCard, 1000 / 120);
    return () => clearInterval(intervalId);
}, [isVideo, selectedVideoCanvasPosition]);
```
:::

`setInterval(detectAndResizeCard, 1000 / 120);`ã—ã¦ã„ã‚‹ã®ã¯ä½“æ„Ÿ120fpsã§å‡¦ç†ã—ã¦ã¿ã‚ˆã†ã‹ãªã¨ã„ã†æ„å›³ã§ã™ã€‚
ã‚«ãƒ¡ãƒ©ã®æ˜ åƒã¨å…±ã«canvasã®è¡¨ç¤ºãŒå¤‰ã‚ã‚‹ãŸã‚ã€é¸æŠç¯„å›²ã®æç”»ã®å‡¦ç†ã‚‚å…¥ã‚Œã¦ã„ã¾ã™ã€‚

#### ç¯„å›²é¸æŠã®åº§æ¨™å–å¾—å‡¦ç†

![é¸æŠç¯„å›²](/images/tcg_recognition_browser_camera/select.gif)

ã‚«ãƒ¡ãƒ©ã‚’æ˜ ã—ã¦ã„ã‚‹canvasä¸Šã‚’ãƒ‰ãƒ©ãƒƒã‚°ã™ã‚‹ã¨ã¿ã‚‡ãƒ¼ã‚“ã¨é¸æŠç¯„å›²ãŒæŒ‡å®šã•ã‚Œã‚‹ã‚„ã¤ã§ã™ã€‚

:::details ç¯„å›²é¸æŠã®åº§æ¨™å–å¾—å‡¦ç†
```typescript
// ã‚­ãƒ£ãƒ³ãƒã‚¹å†…ã®ä½ç½®ã‚’å®Ÿéš›ã®è§£åƒåº¦ã«åˆã‚ã›ã‚‹ãŸã‚ã®é–¢æ•°
const adjustForCanvasScale = (clientX: number, clientY: number) => {
  if (!refVideoCanvas.current)
    return {
      x: 0,
      y: 0,
    };
  const videoCanvas = refVideoCanvas.current;

  const rect = videoCanvas.getBoundingClientRect();
  const scaleX = videoCanvas.width / rect.width;
  const scaleY = videoCanvas.height / rect.height;

  return {
    x: (clientX - rect.left) * scaleX,
    y: (clientY - rect.top) * scaleY,
  };
};

/**
 * ãƒ¢ãƒã‚¤ãƒ«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ç¦æ­¢å‡¦ç†
 */
const scrollNo = React.useCallback((e: TouchEvent) => {
  if (e.cancelable) {
    e.preventDefault();
  }
}, []);

const onTouchStartVideoCanvas: React.TouchEventHandler<HTMLCanvasElement> = (
  e,
) => {
  const touch = e.touches[0];
  const position = adjustForCanvasScale(touch.clientX, touch.clientY);
  document.addEventListener("touchmove", scrollNo, { passive: false });
  document.body.style.overflow = "hidden";

  setSelectedVideoCanvasPosition({
    from: position,
    to: position,
  });

  setIsSelectingVideoCanvasPosition(true);
};

const onMouseDownVideoCanvas: React.MouseEventHandler<HTMLCanvasElement> = (
  e,
) => {
  const position = adjustForCanvasScale(e.clientX, e.clientY);
  document.addEventListener("touchmove", scrollNo, { passive: false });
  document.body.style.overflow = "hidden";

  setSelectedVideoCanvasPosition({
    from: position,
    to: position,
  });

  setIsSelectingVideoCanvasPosition(true);
};

const onTouchMoveVideoCanvas: React.TouchEventHandler<HTMLCanvasElement> = (
  e,
) => {
  if (!isSelectingVideoCanvasPosition) return;

  const touch = e.touches[0];
  const position = adjustForCanvasScale(touch.clientX, touch.clientY);

  setSelectedVideoCanvasPosition((prevSelection) => ({
    ...prevSelection,
    to: position,
  }));
};

const onMouseMoveVideoCanvas: React.MouseEventHandler<HTMLCanvasElement> = (
  e,
) => {
  if (!isSelectingVideoCanvasPosition) return;

  const position = adjustForCanvasScale(e.clientX, e.clientY);

  setSelectedVideoCanvasPosition((prevSelection) => ({
    ...prevSelection,
    to: position,
  }));
};

const onTouchEndVideoCanvas: React.TouchEventHandler<
  HTMLCanvasElement
> = () => {
  document.body.style.overflow = "auto";
  document.removeEventListener("touchmove", scrollNo);
  setIsSelectingVideoCanvasPosition(false);
};

const onMouseUpVideoCanvas: React.MouseEventHandler<
  HTMLCanvasElement
> = () => {
  document.body.style.overflow = "auto";
  document.removeEventListener("touchmove", scrollNo);
  setIsSelectingVideoCanvasPosition(false);
};
```
:::

`onMouseDown`ã¨`onTouchStart`ã¨ä¼¼ãŸã‚ˆã†ãªå‡¦ç†ãŒã‚ã‚Šã¾ã™ãŒPCã®ã¨ãã¯onMouseã€ã‚¹ãƒãƒ›ã®ã¨ãã¯onTouchã§ã‚¤ãƒ™ãƒ³ãƒˆãŒå®Ÿè¡Œã•ã‚Œã‚‹ã®ã§2ã¤ã®å‡¦ç†ãŒã‚ã‚Šã¾ã™ã€‚
å¾Œã¯ãƒ‰ãƒ©ãƒƒã‚°ä¸­ã¯å¦™ãªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãŒç™ºç”Ÿã—ãªã„ã‚ˆã†ã«ã™ã‚‹å‡¦ç†ã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚

#### ç¯„å›²é¸æŠã‹ã‚‰åˆ¥ã®canvasã«æç”»ã¨å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è­˜åˆ¥å‡¦ç†

ã“ã“ã‹ã‚‰ãŒã‚ˆã†ã‚„ãWebãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ä½œæˆã—ãŸå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ç”»åƒèªè­˜ã™ã‚‹å‡¦ç†ã«ãªã‚Šã¾ã™ã€‚

:::details ç¯„å›²é¸æŠã‹ã‚‰åˆ¥ã®canvasã«æç”»ã¨å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è­˜åˆ¥å‡¦ç†
```typescript
const refSelectedCardCanvas = React.useRef<HTMLCanvasElement>(null);

const onClickSelectedCardButton: React.MouseEventHandler<
  HTMLButtonElement
> = async () => {
  if (!generalCardImageTFModel) return;

  if (!refSelectedCardCanvas.current) return;
  const selectedCardCanvas = refSelectedCardCanvas.current;
  const selectedCardCanvasContext = selectedCardCanvas.getContext("2d", {
    willReadFrequently: true,
  });
  if (!selectedCardCanvasContext) return;

  if (!refVideoCanvas.current) return;
  const videoCanvas = refVideoCanvas.current;
  const videoCanvasContext = videoCanvas.getContext("2d", {
    willReadFrequently: true,
  });
  if (!videoCanvasContext) return;

  // çŸ©å½¢é¸æŠã®ç®‡æ‰€ã‚’å–å¾—
  const { from, to } = selectedVideoCanvasPosition;
  const width = from.x < to.x ? to.x - from.x : from.x - to.x;
  const height = from.y < to.y ? to.y - from.y : from.y - to.y;
  const x = from.x < to.x ? from.x : to.x;
  const y = from.y < to.y ? from.y : to.y;
  selectedCardCanvas.width = width;
  selectedCardCanvas.height = height;
  selectedCardCanvasContext.drawImage(
    videoCanvas,
    x,
    y,
    width,
    height,
    0,
    0,
    width,
    height,
  );

  if (width === 0 || height === 0) return;

  const imageData = selectedCardCanvasContext.getImageData(
    0,
    0,
    selectedCardCanvas.width,
    selectedCardCanvas.height,
  );

  setSelectedCard({
    loading: true,
    general: undefined,
  });

  await tf.setBackend("webgl");
  await tf.ready();

  tf.tidy(() => {
    const tensor = tf.browser
      .fromPixels(imageData)
      .resizeNearestNeighbor([cardSize.width, cardSize.height]) // ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ã¦ãƒªã‚µã‚¤ã‚º
      .toFloat()
      .div(tf.scalar(255.0))
      .expandDims(0);

    const prediction = generalCardImageTFModel.predict(tensor);
    // @ts-ignore
    const maxIndex = (prediction.argMax(-1) as tf.Tensor).dataSync()[0];

    const general = GeneralsJSON[maxIndex];

    setSelectedCard({
      loading: false,
      general,
    });
  });
};
```
:::

`await tf.setBackend("webgl");`ã¨`await tf.ready();`ã¯WebGLã‚’ä½¿ã†ãŸã‚ã®å‡¦ç†ã§ã€`tf.tidy`ã¯ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’é˜²ããŸã‚ã®å‡¦ç†ã§ã™ã€‚

`resizeNearestNeighbor([cardSize.width, cardSize.height])`ã¯[å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½œæˆ](#å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½œæˆ-1)ã§æŒ‡å®šã—ãŸã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚ºã—ã¦ã„ã¾ã™ã€‚

å€‹äººçš„ã«ãƒ¢ãƒ¤ã£ã¦ã„ã‚‹å®Ÿè£…ã¨ã—ã¦

```typescript
const prediction = generalCardImageTFModel.predict(tensor);
// @ts-ignore
const maxIndex = (prediction.argMax(-1) as tf.Tensor).dataSync()[0];

const general = GeneralsJSON[maxIndex];
```

ã®éƒ¨åˆ†ã®æ¤œå‡ºçµæœã®å–å¾—ãªã®ã§ã™ãŒã€indexã˜ã‚ƒãªãã¦ãƒ¢ãƒ‡ãƒ«ä½œæˆæ™‚ã«

```typescript
const { xs, ys, classNames } = await loadImagesFromDirectories();
```

ã¨ã‚«ãƒ¼ãƒ‰ã®åå‰ã‚’classNamesã«ä¿å­˜ã—ã¦ã„ãŸã®ã§ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã«ã‚‚çµ„ã¿å…¥ã‚Œã¦åå‰ã§ã§ããªã„ã‹ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚
å¾Œã¯ã€TypeScriptã§è£œå®Œã•ã‚Œã¦ã„ã‚‹æ§˜ã§å‹ãŒãªã„å¤‰æ•°ãŒã‚ã£ãŸã‚Šã‚‚ã™ã‚‹ã®ã§ã€ã ã„ã¶ç–‘å¿ƒæš—é¬¼ãªã¨ã“ã‚ãŒã‚ã‚Šã¾ã™ãŒã€ã¨ã‚Šã‚ãˆãšå‹•ã„ã¦ã„ã‚‹ã®ã§ã‚ˆã—ã¨ã—ã¦ã„ã¾ã™ã€‚

# æ„Ÿæƒ³

- é›£ã—ã„ã¨æ€ã£ãŸå®Ÿè£…ã‚‚ChatGPTã§ã§ãã¾ã—ãŸã€‚
- åˆã‚ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã§å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸç”»åƒèªè­˜ã‚’ã—ãŸã®ã§ä»–ã«ã‚‚æ´»ç”¨ã—ãŸã„ãªã¨æ€ã„ã¾ã—ãŸã€‚
- å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®è€ƒæ…®ãŒå¤§å¤‰ã§ã—ãŸã€‚
- ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§ã‚‚Node.jsä¸Šã§ã‚‚canvasãŒå¤§æ´»èºã§ã—ãŸã€‚
